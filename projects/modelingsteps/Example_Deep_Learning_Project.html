
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Example Deep Learning Project &#8212; Neuromatch Academy: Deep Learning</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.e8e5499552300ddf5d7adccae7cc3b70.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="shortcut icon" href="../../_static/nma-dl-logo-square-4xp.jpeg"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Notebook with codes for projects" href="../code/intro.html" />
    <link rel="prev" title="Example Model Project: the Train Illusion" href="TrainIllusionModelingProjectDL.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      <img src="../../_static/nma-dl-logo-square-4xp.jpeg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Neuromatch Academy: Deep Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../tutorials/intro.html">
   Introduction
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/Schedule/schedule_intro.html">
   Schedule
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/Schedule/daily_schedules.html">
     General schedule
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/Schedule/shared_calendars.html">
     Shared calendars
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/Schedule/timezone_widget.html">
     Timezone widget
    </a>
   </li>
  </ul>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/TechnicalHelp/tech_intro.html">
   Technical Help
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../tutorials/TechnicalHelp/Jupyterbook.html">
     Using jupyterbook
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/TechnicalHelp/Tutorial_colab.html">
       Using Google Colab
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/TechnicalHelp/Tutorial_kaggle.html">
       Using Kaggle
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/TechnicalHelp/Discord.html">
     Using Discord
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  The Basics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/W1D1_BasicsAndPytorch/chapter_title.html">
   Basics And Pytorch (W1D1)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/W1D1_BasicsAndPytorch/student/W1D1_Tutorial1.html">
     Tutorial 1: PyTorch
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/W1D2_LinearDeepLearning/chapter_title.html">
   Linear Deep Learning (W1D2)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/W1D2_LinearDeepLearning/student/W1D2_Tutorial1.html">
     Tutorial 1: Gradient Descent and AutoGrad
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/W1D2_LinearDeepLearning/student/W1D2_Tutorial2.html">
     Tutorial 2: Learning Hyperparameters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/W1D2_LinearDeepLearning/student/W1D2_Tutorial3.html">
     Tutorial 3: Deep linear neural networks
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/W1D3_MultiLayerPerceptrons/chapter_title.html">
   Multi Layer Perceptrons (W1D3)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/W1D3_MultiLayerPerceptrons/student/W1D3_Tutorial1.html">
     Tutorial 1: Biological vs. Artificial neurons
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/W1D3_MultiLayerPerceptrons/student/W1D3_Tutorial2.html">
     Tutorial 2: Deep MLPs
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/W1D4_Optimization/chapter_title.html">
   Optimization (W1D4)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/W1D4_Optimization/student/W1D4_Tutorial1.html">
     Tutorial 1: Optimization techniques
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/W1D5_Regularization/chapter_title.html">
   Regularization (W1D5)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/W1D5_Regularization/student/W1D5_Tutorial1.html">
     Tutorial 1: Regularization techniques part 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/W1D5_Regularization/student/W1D5_Tutorial2.html">
     Tutorial 2: Regularization techniques part 2
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Doing more with fewer parameters
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/W2D1_ConvnetsAndRecurrentNeuralNetworks/chapter_title.html">
   Convnets And Recurrent Neural Networks (W2D1)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/W2D1_ConvnetsAndRecurrentNeuralNetworks/student/W2D1_Tutorial1.html">
     Tutorial 1: Introduction to CNNs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/W2D1_ConvnetsAndRecurrentNeuralNetworks/student/W2D1_Tutorial2.html">
     Tutorial 2: Training loop of CNNs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/W2D1_ConvnetsAndRecurrentNeuralNetworks/student/W2D1_Tutorial3.html">
     Tutorial 3: Introduction to RNNs
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/W2D2_ModernConvnets/chapter_title.html">
   Modern Convnets (W2D2)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/W2D2_ModernConvnets/student/W2D2_Tutorial1.html">
     Tutorial 1: Learn how to use modern convnets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/W2D2_ModernConvnets/student/W2D2_Tutorial2.html">
     Tutorial 2: Facial recognition using modern convnets
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/W2D3_ModernRecurrentNeuralNetworks/chapter_title.html">
   Modern Recurrent Neural Networks (W2D3)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/W2D3_ModernRecurrentNeuralNetworks/student/W2D3_Tutorial1.html">
     Tutorial 1: Modeling sequencies and encoding text
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/W2D3_ModernRecurrentNeuralNetworks/student/W2D3_Tutorial2.html">
     Tutorial 2: Modern RNNs and their variants
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/W2D4_AttentionAndTransformers/chapter_title.html">
   Attention And Transformers (W2D4)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/W2D4_AttentionAndTransformers/student/W2D4_Tutorial1.html">
     Tutorial 1: Learn how to work with Transformers
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/W2D5_GenerativeModels/chapter_title.html">
   Generative Models (W2D5)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/W2D5_GenerativeModels/student/W2D5_Tutorial1.html">
     Tutorial 1: Variational Autoencoders (VAEs)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/W2D5_GenerativeModels/student/W2D5_Tutorial2.html">
     Tutorial 2: Introduction to GANs and Density Ratio Estimation Perspective of GANs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/W2D5_GenerativeModels/student/W2D5_Tutorial3.html">
     Tutorial 3: Conditional GANs and Implications of GAN Technology
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Advanced topics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/W3D1_UnsupervisedAndSelfSupervisedLearning/chapter_title.html">
   Unsupervised And Self Supervised Learning (W3D1)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/W3D1_UnsupervisedAndSelfSupervisedLearning/student/W3D1_Tutorial1.html">
     Tutorial 1: Un/Self-supervised learning methods
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/W3D2_BasicReinforcementLearning/chapter_title.html">
   Basic Reinforcement Learning (W3D2)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/W3D2_BasicReinforcementLearning/student/W3D2_Tutorial1.html">
     Tutorial 1: Introduction to Reinforcement Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/W3D3_ReinforcementLearningForGames/chapter_title.html">
   Reinforcement Learning For Games (W3D3)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/W3D3_ReinforcementLearningForGames/student/W3D3_Tutorial1.html">
     Tutorial 1: Learn to play games with RL
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/W3D4_ContinualLearning/chapter_title.html">
   Continual Learning (W3D4)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/W3D4_ContinualLearning/student/W3D4_Tutorial1.html">
     Tutorial 1: Introduction to Continual Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/W3D4_ContinualLearning/student/W3D4_Tutorial2.html">
     Tutorial 2: Out-of-distribution (OOD) Learning
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Project Booklet
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../README.html">
   Introduction to projects
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../docs/project_guidance.html">
   Daily guide for projects
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="intro.html">
   Modeling Step-by-Step Guide
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
  <label for="toctree-checkbox-18">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="ModelingSteps_1through2_DL.html">
     Modeling Steps 1 - 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ModelingSteps_3through4_DL.html">
     Modeling Steps 3 - 4
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ModelingSteps_5through6_DL.html">
     Modeling Steps 5 - 6
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ModelingSteps_7through9_DL.html">
     Modeling Steps 7 - 9
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ModelingSteps_10_DL.html">
     Modeling Steps 10
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="TrainIllusionDataProjectDL.html">
     Example Data Project: the Train Illusion
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="TrainIllusionModelingProjectDL.html">
     Example Model Project: the Train Illusion
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Example Deep Learning Project
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../code/intro.html">
   Notebook with codes for projects
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
  <label for="toctree-checkbox-19">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../code/segmentation_denoising.html">
     Segmentation and Denoising
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../code/PoseEstimation.html">
     Animal Pose Estimation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../code/RLymipcs.html">
     NMA Robolympics: Controlling robots using reinforcement learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../code/algonauts_videos.html">
     Load algonauts videos
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../docs/project_templates.html">
   Project Templates
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/projects/modelingsteps/Example_Deep_Learning_Project.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/NeuromatchAcademy/course-content-dl"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/NeuromatchAcademy/course-content-dl/issues/new?title=Issue%20on%20page%20%2Fprojects/modelingsteps/Example_Deep_Learning_Project.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Example Deep Learning Project
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#objectives">
   Objectives
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#setup">
   Setup
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#figure-settings">
     Figure settings
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#plotting-functions">
     Plotting functions
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-retrieval">
     Data retrieval
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-1-question">
   Step 1: Question
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-2-literature-review">
   Step 2: literature review
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-3-ingredients">
   Step 3: ingredients
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-ingredients">
     Data ingredients
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-ingredients">
     Model ingredients
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-4-hypotheses">
   Step 4: hypotheses
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-5-toolkit-selection">
   Step 5: toolkit selection
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-6-model-drafting">
   Step 6: model drafting
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-7-model-implementation">
   Step 7: model implementation
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#build-model">
     Build model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-8-modeling-completion">
   Step 8: Modeling completion
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-9-model-evaluation">
   Step 9: Model evaluation
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-10-publication">
   Step 10: publication
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <p><a href="https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/main/projects/modelingsteps/Example_Deep_Learning_Project.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<div class="section" id="example-deep-learning-project">
<h1>Example Deep Learning Project<a class="headerlink" href="#example-deep-learning-project" title="Permalink to this headline">¶</a></h1>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong> Marius ‘t Hart, Megan Peters, Vladimir Haltakov, Paul Schrater, Gunnar Blohm</p>
<p><strong>Production editor:</strong> Spiros Chavlis</p>
<p><strong>Our 2021 Sponsors, including Presenting Sponsor Facebook Reality Labs</strong></p>
<p align='center'><img src='https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True'/></p></div>
<hr class="docutils" />
<div class="section" id="objectives">
<h1>Objectives<a class="headerlink" href="#objectives" title="Permalink to this headline">¶</a></h1>
<p>We’re interested in automatically classifying movement. There is a great dataset (MoVi) with different modalities of movement recordings (videos, visual markers, accelerometers, skeletal motion reconstructions, etc). We will use a sub-set of this data, i.e. estimated skeletal motion, to perform a pilot study investigating whether we can classify different movements from the skeletal motion. And if so, which skeletal motions (if not all) are neccessary for good decoding performance?</p>
<p>Please check out the different resources below to better understand the MoVi dataset and learn more about the movements.</p>
<p><strong>Resources</strong>:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0253157">see MoVi paper here</a></p></li>
<li><p><a class="reference external" href="https://github.com/saeed1262/MoVi-Toolbox">GitHub page of MoVi</a></p></li>
<li><p><a class="reference external" href="https://www.biomotionlab.ca/movi/">MoVi website and description</a></p></li>
<li><p><a class="reference external" href="https://dataverse.scholarsportal.info/dataset.xhtml?persistentId=doi:10.5683/SP2/JRHDRN">full MoVi dataset (not needed for this demo)</a></p></li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">¶</a></h1>
<p>For your own project, you can put together a colab notebook by copy-pasting bits of code from the tutorials. We still recommend keeping the 4 setup cells at the top, like here; Imports, Figure Settings, Plotting functions, and Data retrieval.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>
<span class="c1"># get some matrices and plotting:</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># get some pytorch:</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">MaxPool1d</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="c1"># confusion matrix from sklearn</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>

<span class="c1"># to get some idea of how long stuff will take to complete:</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="c1"># to see how unbalanced the data is:</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="figure-settings">
<h2>Figure settings<a class="headerlink" href="#figure-settings" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Figure settings</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span> <span class="c1">#interactive display</span>

<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/NeuromatchAcademy/content-creation/main/nma.mplstyle&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="plotting-functions">
<h2>Plotting functions<a class="headerlink" href="#plotting-functions" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Plotting functions</span>

<span class="k">def</span> <span class="nf">plotConfusionMatrix</span><span class="p">(</span><span class="n">real_labels</span><span class="p">,</span> <span class="n">predicted_labels</span><span class="p">,</span> <span class="n">label_names</span><span class="p">):</span>

  <span class="c1"># conver the labels to integers:</span>
  <span class="n">real_labels</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">real_labels</span><span class="p">]</span>
  <span class="n">predicted_labels</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">predicted_labels</span><span class="p">]</span>
  <span class="n">tick_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">label_names</span><span class="p">]</span>
  
  <span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">real_labels</span><span class="p">,</span> <span class="n">predicted_labels</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="s1">&#39;true&#39;</span><span class="p">)</span>
  
  <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cm</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tick_names</span><span class="p">)),</span><span class="n">tick_names</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tick_names</span><span class="p">)),</span><span class="n">tick_names</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;predicted move&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;real move&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="data-retrieval">
<h2>Data retrieval<a class="headerlink" href="#data-retrieval" title="Permalink to this headline">¶</a></h2>
<p>Run this cell to download the data for this example project.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Data retrieval</span>
<span class="c1"># @markdown Run this cell to download the data for this example project.</span>
<span class="kn">import</span> <span class="nn">io</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;https://osf.io/mnqb7/download&#39;</span><span class="p">)</span>
<span class="k">if</span> <span class="n">r</span><span class="o">.</span><span class="n">status_code</span> <span class="o">!=</span> <span class="mi">200</span><span class="p">:</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Failed to download data&#39;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
  <span class="n">train_moves</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">),</span> <span class="n">allow_pickle</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="s1">&#39;train_moves&#39;</span><span class="p">]</span>
  <span class="n">train_labels</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">),</span> <span class="n">allow_pickle</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="s1">&#39;train_labels&#39;</span><span class="p">]</span>
  <span class="n">test_moves</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">),</span> <span class="n">allow_pickle</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="s1">&#39;test_moves&#39;</span><span class="p">]</span>
  <span class="n">test_labels</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">),</span> <span class="n">allow_pickle</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="s1">&#39;test_labels&#39;</span><span class="p">]</span>
  <span class="n">label_names</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">),</span> <span class="n">allow_pickle</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="s1">&#39;label_names&#39;</span><span class="p">]</span>
  <span class="n">joint_names</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">),</span> <span class="n">allow_pickle</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="s1">&#39;joint_names&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="step-1-question">
<h1>Step 1: Question<a class="headerlink" href="#step-1-question" title="Permalink to this headline">¶</a></h1>
<p>There are many different questions we could ask with the MoVi dataset. We will start with a simple question: <strong>“Can we classify movements from skeletal motion data, and if so, which body parts are the most informative ones?”</strong></p>
<p>Our goal is to perform a <em>pilot</em> study to see if this is possible in principle. We will therefore use “ground truth” skeletal motion data that has been computed using an inference algorithm (see <a class="reference external" href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0253157">MoVi paper</a>). If this works out, then as a next step we might want to use the raw sensor data or even videos…</p>
<p>The ultimate goal could for example be to figure out which body parts to record movements from (e.g. is just a wristband enough?) to classify movement.</p>
</div>
<hr class="docutils" />
<div class="section" id="step-2-literature-review">
<h1>Step 2: literature review<a class="headerlink" href="#step-2-literature-review" title="Permalink to this headline">¶</a></h1>
<p>Most importantly, our literature review needs to address the following:</p>
<ul class="simple">
<li><p>what modeling approaches make it possible to classify time series data?</p></li>
<li><p>how is human motion captured?</p></li>
<li><p>what exactly is in the MoVi dataset?</p></li>
<li><p>what is known regarding classification of human movement based on different measurements?</p></li>
</ul>
<p>What we learn from the literature review is too long to write out here… But we would like to point out that human motion classification has been done; we’re not proposing a very novel project here. But that’s ok for an NMA project!</p>
</div>
<hr class="docutils" />
<div class="section" id="step-3-ingredients">
<h1>Step 3: ingredients<a class="headerlink" href="#step-3-ingredients" title="Permalink to this headline">¶</a></h1>
<div class="section" id="data-ingredients">
<h2>Data ingredients<a class="headerlink" href="#data-ingredients" title="Permalink to this headline">¶</a></h2>
<p>After downloading the data, we should have 6 numpy arrays:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">train_moves</span></code>: the training set of 1032 movements</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">train_labels</span></code>: the class labels for each of the 1032 training movements</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">test_moves</span></code>: the test set of 172 movements</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">test_labels</span></code>: the class labels for each of the 172 test movements</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">label_names</span></code>: text labels for the values in the two arrays of class labels</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">joint_names</span></code>: the names of the 24 joints used in each movement</p></li>
</ul>
<p>We’ll take a closer look at the data below. <em>Note</em>: data is split into training and test sets. If you don’t know what that means, NMA-DL will teach you!</p>
<p><strong>Inputs</strong>:</p>
<p>For simplicity, we take the first 24 joints of the whole MoVi dataset including all major limbs. The data was in an exponential map format, which has 3 rotations/angles for each joint (pitch, yaw, roll). The advantage of this type of data is that it is (mostly) agnostic about body size or shape. And since we care about movements only, we choose this representation of the data (there are other representations in the full data set).</p>
<p>Since the joints are simply points, the 3rd angle (i.e. roll) contained no information, and that is already dropped from the data that we pre-formatted for this demo project. That is, the movements of each joint are described by 2 angles, that change over time. Furthermore, we normalized all the angles/rotations to fall between 0 and 1 so they are good input for PyTorch.</p>
<p>Finally, the movements originally took various amounts of time, but we need the same input for each movement, so we sub-sampled and (linearly) interpolated the data to have 75 timepoints.</p>
<p>Our training data is supposed to have 1032 movements, 2 x 24 joints = 48 channels and 75 timepoints. Let’s check and make sure:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">train_moves</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1032, 48, 75)
</pre></div>
</div>
</div>
</div>
<p>Cool!</p>
<p><strong>Joints</strong>:</p>
<p>For each movement we have 2 angles from 24 joints. Which joints are these?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">joint_no</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">24</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">joint_no</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">joint_names</span><span class="p">[</span><span class="n">joint_no</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0: Pelvis
1: LeftHip
2: RightHip
3: Spine1
4: LeftKnee
5: RightKnee
6: Spine2
7: LeftAnkle
8: RightAnkle
9: Spine3
10: LeftFoot
11: RightFoot
12: Neck
13: LeftCollar
14: RightCollar
15: Head
16: LeftShoulder
17: RightShoulder
18: LeftElbow
19: RightElbow
20: LeftWrist
21: RightWrist
22: LeftHand
23: RightHand
</pre></div>
</div>
</div>
</div>
<p><strong>Labels</strong>:</p>
<p>Let’s have a look at the <code class="docutils literal notranslate"><span class="pre">train_labels</span></code> array too:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">train_labels</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[ 0  1  4 ...  6  2 11]
(1032,)
</pre></div>
</div>
</div>
</div>
<p>The labels are numbers, and there are 1032 of them, so that matches the number of movements in the data set. There are text versions too in the array called <code class="docutils literal notranslate"><span class="pre">label_names</span></code>. Let’s have a look. There are supposed to be 14 movement classes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># let&#39;s check the values of the train_labels array:</span>
<span class="n">label_numbers</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">train_labels</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">label_numbers</span><span class="p">)</span>

<span class="c1"># and use them as indices into the label_names array:</span>
<span class="k">for</span> <span class="n">label_no</span> <span class="ow">in</span> <span class="n">label_numbers</span><span class="p">:</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">label_no</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">label_names</span><span class="p">[</span><span class="n">label_no</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]
0: crawling
1: throw/catch
2: walking
3: running_in_spot
4: cross_legged_sitting
5: hand_clapping
6: scratching_head
7: kicking
8: phone_talking
9: sitting_down
10: checking_watch
11: pointing
12: hand_waving
13: taking_photo
</pre></div>
</div>
</div>
</div>
<p>The test data set has similar data, but fewer movements. That’s ok. What’s important is that both the training and test datasets have an even spread of movement types, i.e. we want them to be balanced. Let’s see how balanced the data is:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Counter</span><span class="p">(</span><span class="n">train_labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Counter({0: 74,
         1: 74,
         2: 73,
         3: 73,
         4: 73,
         5: 73,
         6: 74,
         7: 74,
         8: 74,
         9: 74,
         10: 74,
         11: 74,
         12: 74,
         13: 74})
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Counter</span><span class="p">(</span><span class="n">test_labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Counter({0: 12,
         1: 12,
         2: 13,
         3: 13,
         4: 13,
         5: 13,
         6: 12,
         7: 12,
         8: 12,
         9: 12,
         10: 12,
         11: 12,
         12: 12,
         13: 12})
</pre></div>
</div>
</div>
</div>
<p>So that looks more or less OK. Movements 2, 3, 4 and 5 occur once more in the training data than the other movements, and one time fewer in the test data. Not perfect, but probably doesn’t matter that much.</p>
</div>
<div class="section" id="model-ingredients">
<h2>Model ingredients<a class="headerlink" href="#model-ingredients" title="Permalink to this headline">¶</a></h2>
<p><strong>“Mechanisms”</strong>:</p>
<ul class="simple">
<li><p>Feature engineering? –&gt; Do we need anything else aside from angular time courses? For now we choose to only use the angular time courses (exponential maps), as our ultimate goal is to see how many joints we need for accurate movement classification so that we can decrease the number of measurements or devices for later work.</p></li>
<li><p>Feature selection? –&gt; Which joint movements are most informative? These are related to our research questions and hypotheses, so this project will explicitly investigate which joints are most informative.</p></li>
<li><p>Feature grouping? –&gt; Instead of trying all possible combinations of joints (very many) we could focus on limbs, by grouping joints. We could also try the model on individual joints.</p></li>
<li><p>Classifier? –&gt; For our classifier we would like to keep it as simple as possible, but we will decide later.</p></li>
<li><p>Input? –&gt; The training data (movements and labels) will be used to train the classifier.</p></li>
<li><p>Output? –&gt; The test data will be used as input for the trained model and we will see if the predicted labels are the same as the actual labels.</p></li>
</ul>
</div>
</div>
<hr class="docutils" />
<div class="section" id="step-4-hypotheses">
<h1>Step 4: hypotheses<a class="headerlink" href="#step-4-hypotheses" title="Permalink to this headline">¶</a></h1>
<p>Since humans can easily distinguish different movement types from video data and also more abstract “stick figures”, a DL model should also be able to do so. Therefore, our hypotheses are more detailed with respect to parameters influencing model performance (and not just whether it will work or not).</p>
<p>Remember, we’re interested in seeing how many joints are needed for classification. So we could hypothezise (Hypothesis 1) that arm and leg motions are sufficient for classification (meaning: head and torso data is not needed).</p>
<ul class="simple">
<li><p>Hypothesis 1: The performance of a model with four limbs plus torso and head is not higher than the performance of a model with only limbs.</p></li>
</ul>
<p>We could also hypothesize that data from only one side of the body is sufficient (Hypothesis 2), e.g. the right side, since our participants are right handed.</p>
<ul class="simple">
<li><p>Hypothesis 2: A model using only joints in the right arm will outperform a model using only the joints in the left arm.</p></li>
</ul>
<p>Writing those in mathematical terms:</p>
<ul class="simple">
<li><p>Hypothesis 1: <span class="math notranslate nohighlight">\(\mathbb{E}(perf_{limbs})&gt;\mathbb{E}(perf_{torso})\)</span></p></li>
<li><p>Hypothesis 2: <span class="math notranslate nohighlight">\(\mathbb{E}(perf_{right arm})&gt;\mathbb{E}(perf_{left arm})\)</span></p></li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="step-5-toolkit-selection">
<h1>Step 5: toolkit selection<a class="headerlink" href="#step-5-toolkit-selection" title="Permalink to this headline">¶</a></h1>
<p>We need a toolkit that can deal with time-varying data as input (e.g. 1d convnet, LSTM, transformer…). We want to keep it as simple as possible to start with. So let’s run with a 1d convnet. It allows us to answer our question, it will be able to speak to our hypotheses, and hopefully we can achieve our goal to see if automatic movement classification based on (sparse) body movement data is possible.</p>
</div>
<hr class="docutils" />
<div class="section" id="step-6-model-drafting">
<h1>Step 6: model drafting<a class="headerlink" href="#step-6-model-drafting" title="Permalink to this headline">¶</a></h1>
<p>Here is our sketch of the model we wanted to build…</p>
<p align='center'><img src='https://github.com/NeuromatchAcademy/course-content-dl/blob/main/projects/static/DL_model_schematic.jpg?raw=True'/></p></div>
<hr class="docutils" />
<div class="section" id="step-7-model-implementation">
<h1>Step 7: model implementation<a class="headerlink" href="#step-7-model-implementation" title="Permalink to this headline">¶</a></h1>
<p>It’s finally time to write some deep learning code… so here we go!</p>
<p>The cell below creates an object class, and is based on https://pytorch.org/tutorials/beginner/basics/data_tutorial.html on the PyTorch website, adapted to work with our data.</p>
<p>It is based on the <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> object class in PyTorch and this is needed to set up a <code class="docutils literal notranslate"><span class="pre">Dataloader</span></code> object that will be used in the model.</p>
<p>We can tell our dataset object to use the training or test data. We can also tell it which joints to return, so that we can build models that classify movements based on different sets of joints:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MoViJointDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;MoVi dataset.&quot;&quot;&quot;</span>
  
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">joints</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">24</span><span class="p">))):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">      train (boolean): Use the training data, or otherwise the test data.</span>
<span class="sd">      joints (list): Indices of joints to return.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="c1"># select the training or test data:</span>
    <span class="k">if</span> <span class="n">train</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">moves</span> <span class="o">=</span> <span class="n">train_moves</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">train_labels</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">moves</span> <span class="o">=</span> <span class="n">test_moves</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">test_labels</span>
    
    <span class="c1"># convert joint indices to channel indices:</span>
    <span class="n">joints</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">joints</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">channels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">joints</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span><span class="o">+</span> <span class="nb">list</span><span class="p">((</span><span class="n">joints</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># 2 channels per joint</span>
      
  <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">size</span>

  <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">idx</span><span class="p">):</span>
      <span class="n">idx</span> <span class="o">=</span> <span class="n">idx</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    
    <span class="n">sample</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">moves</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">channels</span><span class="p">,:])),</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">sample</span>
</pre></div>
</div>
</div>
</div>
<p>We want to make sure that this object works the way we intended, so we try it out:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create training and test datasets</span>
<span class="n">movi_train</span> <span class="o">=</span> <span class="n">MoViJointDataset</span><span class="p">(</span><span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">movi_test</span> <span class="o">=</span> <span class="n">MoViJointDataset</span><span class="p">(</span><span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">joints</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;TRAINING:&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">movi_train</span><span class="p">)):</span>
  <span class="k">pass</span>
<span class="nb">print</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">movi_train</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">label_names</span><span class="p">[</span><span class="n">movi_train</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="mi">1</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">TESTING:&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">movi_test</span><span class="p">)):</span>
  <span class="k">pass</span>
<span class="nb">print</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">movi_test</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">label_names</span><span class="p">[</span><span class="n">movi_test</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="mi">1</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>TRAINING:
1031
(48, 75) pointing

TESTING:
171
(6, 75) cross_legged_sitting
</pre></div>
</div>
</div>
</div>
<p>So we see the movement number (minus 1), the shape of the dataset (e.g. 48 channels and 75 time points for the training set), and the name of the movement.</p>
<div class="section" id="build-model">
<h2>Build model<a class="headerlink" href="#build-model" title="Permalink to this headline">¶</a></h2>
<p>pytorch expects as input not a single sample, but rather a minibatch of B samples stacked together along the “minibatch dimension”.
So a “1D” CNN in pytorch expects a 3D tensor as input: BxCxT</p>
<ul class="simple">
<li><p><strong>B:</strong> batch size (however many examples are used in batch training)</p></li>
<li><p><strong>C:</strong> channels (up to 24 joints x 2 coordinates)</p></li>
<li><p><strong>T:</strong> timepoints (75 in our case)</p></li>
</ul>
<p>We need <code class="docutils literal notranslate"><span class="pre">Dataloader</span></code> objects that use our <code class="docutils literal notranslate"><span class="pre">MoViJointDataset</span></code> objects to do this. For this we can simply use PyTorch <code class="docutils literal notranslate"><span class="pre">Dataloader</span></code> objects, but it also needs one of our hyperparameters (batch size) to be set:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Hyperparameters</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">14</span> <span class="c1"># is this ever used?</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">516</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>

<span class="c1"># Create training and test datasets</span>
<span class="n">movi_train</span> <span class="o">=</span> <span class="n">MoViJointDataset</span><span class="p">(</span><span class="n">train</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">movi_test</span>  <span class="o">=</span> <span class="n">MoViJointDataset</span><span class="p">(</span><span class="n">train</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>

<span class="c1"># Data loader</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">movi_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">test_loader</span>  <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">movi_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>And we decided to use a simple 1D convnet. We want to specify the number of joints used and then use 2 input channels for every joint (2 dimensions of rotation). At the end of the convnet there are 14 probabilities, 1 for each class of movement, but we convert it to give the index of the highest probability.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Mov1DCNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">njoints</span><span class="o">=</span><span class="mi">24</span><span class="p">):</span>
      
    <span class="nb">super</span><span class="p">(</span><span class="n">Mov1DCNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    
    <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
      <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">njoints</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">56</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
      <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
      <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool1d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
    
    <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
      <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">56</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
      <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
      <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool1d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
    
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">126</span><span class="p">,</span> <span class="mi">2200</span><span class="p">)</span>  <span class="c1"># fix dimensions</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nl</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2200</span><span class="p">,</span> <span class="mi">14</span><span class="p">)</span>
  
  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    
    <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nl</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="c1"># pick the most likely class:</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
</div>
</div>
<p>We can now instantiate the model object, with <em>all</em> joints, and set a criterion and optimizer:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">### ADDING GPU ###</span>
<span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>

<span class="c1"># create the model object:</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Mov1DCNN</span><span class="p">(</span><span class="n">njoints</span><span class="o">=</span><span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># loss and optimizer:</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>And now we are ready to train this model.</p>
<p><strong>This takes up to ~20 seconds!</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train the model</span>
<span class="n">total_step</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
<span class="n">loss_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">acc_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">motions</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
    <span class="n">motions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">motions</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># Run the forward pass</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">motions</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
    <span class="n">loss_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

    <span class="c1"># Backprop and perform Adam optimisation</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="c1"># Track the accuracy</span>
    <span class="n">total</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">acc_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">correct</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s2">], Step [</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">total_step</span><span class="si">}</span><span class="s2">], &quot;</span>
              <span class="sa">f</span><span class="s2">&quot;Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, &quot;</span>
              <span class="sa">f</span><span class="s2">&quot;Accuracy: </span><span class="si">{</span><span class="p">((</span><span class="n">correct</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [1/500], Step [2/2], Loss: 2.6444, Accuracy: 6.98%
Epoch [2/500], Step [2/2], Loss: 2.6401, Accuracy: 6.20%
Epoch [3/500], Step [2/2], Loss: 2.6357, Accuracy: 9.69%
Epoch [4/500], Step [2/2], Loss: 2.6310, Accuracy: 8.33%
Epoch [5/500], Step [2/2], Loss: 2.6244, Accuracy: 9.30%
Epoch [6/500], Step [2/2], Loss: 2.6164, Accuracy: 13.57%
Epoch [7/500], Step [2/2], Loss: 2.6091, Accuracy: 7.95%
Epoch [8/500], Step [2/2], Loss: 2.5909, Accuracy: 17.05%
Epoch [9/500], Step [2/2], Loss: 2.5733, Accuracy: 8.14%
Epoch [10/500], Step [2/2], Loss: 2.5552, Accuracy: 18.80%
Epoch [11/500], Step [2/2], Loss: 2.5255, Accuracy: 10.47%
Epoch [12/500], Step [2/2], Loss: 2.4663, Accuracy: 33.53%
Epoch [13/500], Step [2/2], Loss: 2.4285, Accuracy: 18.02%
Epoch [14/500], Step [2/2], Loss: 2.3954, Accuracy: 19.77%
Epoch [15/500], Step [2/2], Loss: 2.3168, Accuracy: 21.90%
Epoch [16/500], Step [2/2], Loss: 2.3037, Accuracy: 20.93%
Epoch [17/500], Step [2/2], Loss: 2.2891, Accuracy: 14.92%
Epoch [18/500], Step [2/2], Loss: 2.2106, Accuracy: 32.17%
Epoch [19/500], Step [2/2], Loss: 2.1728, Accuracy: 31.98%
Epoch [20/500], Step [2/2], Loss: 2.1207, Accuracy: 30.62%
Epoch [21/500], Step [2/2], Loss: 2.0758, Accuracy: 30.62%
Epoch [22/500], Step [2/2], Loss: 2.0112, Accuracy: 43.60%
Epoch [23/500], Step [2/2], Loss: 1.9146, Accuracy: 52.33%
Epoch [24/500], Step [2/2], Loss: 1.8849, Accuracy: 46.90%
Epoch [25/500], Step [2/2], Loss: 1.8408, Accuracy: 51.74%
Epoch [26/500], Step [2/2], Loss: 1.8744, Accuracy: 35.66%
Epoch [27/500], Step [2/2], Loss: 1.8619, Accuracy: 34.50%
Epoch [28/500], Step [2/2], Loss: 1.7868, Accuracy: 45.93%
Epoch [29/500], Step [2/2], Loss: 1.7334, Accuracy: 48.64%
Epoch [30/500], Step [2/2], Loss: 1.6448, Accuracy: 55.23%
Epoch [31/500], Step [2/2], Loss: 1.6358, Accuracy: 53.49%
Epoch [32/500], Step [2/2], Loss: 1.6626, Accuracy: 49.42%
Epoch [33/500], Step [2/2], Loss: 1.6181, Accuracy: 50.97%
Epoch [34/500], Step [2/2], Loss: 1.5846, Accuracy: 48.64%
Epoch [35/500], Step [2/2], Loss: 1.5973, Accuracy: 50.00%
Epoch [36/500], Step [2/2], Loss: 1.5414, Accuracy: 52.52%
Epoch [37/500], Step [2/2], Loss: 1.5328, Accuracy: 46.71%
Epoch [38/500], Step [2/2], Loss: 1.4948, Accuracy: 53.49%
Epoch [39/500], Step [2/2], Loss: 1.6476, Accuracy: 38.76%
Epoch [40/500], Step [2/2], Loss: 1.6556, Accuracy: 39.92%
Epoch [41/500], Step [2/2], Loss: 1.6499, Accuracy: 35.85%
Epoch [42/500], Step [2/2], Loss: 1.5014, Accuracy: 47.48%
Epoch [43/500], Step [2/2], Loss: 1.5350, Accuracy: 43.22%
Epoch [44/500], Step [2/2], Loss: 1.5139, Accuracy: 49.22%
Epoch [45/500], Step [2/2], Loss: 1.4106, Accuracy: 53.68%
Epoch [46/500], Step [2/2], Loss: 1.3868, Accuracy: 57.95%
Epoch [47/500], Step [2/2], Loss: 1.3978, Accuracy: 57.17%
Epoch [48/500], Step [2/2], Loss: 1.3262, Accuracy: 56.20%
Epoch [49/500], Step [2/2], Loss: 1.3816, Accuracy: 53.88%
Epoch [50/500], Step [2/2], Loss: 1.3428, Accuracy: 60.08%
Epoch [51/500], Step [2/2], Loss: 1.3654, Accuracy: 53.10%
Epoch [52/500], Step [2/2], Loss: 1.2868, Accuracy: 60.47%
Epoch [53/500], Step [2/2], Loss: 1.2985, Accuracy: 55.81%
Epoch [54/500], Step [2/2], Loss: 1.2942, Accuracy: 55.62%
Epoch [55/500], Step [2/2], Loss: 1.2690, Accuracy: 59.69%
Epoch [56/500], Step [2/2], Loss: 1.1731, Accuracy: 64.73%
Epoch [57/500], Step [2/2], Loss: 1.1836, Accuracy: 61.82%
Epoch [58/500], Step [2/2], Loss: 1.2318, Accuracy: 58.14%
Epoch [59/500], Step [2/2], Loss: 1.1969, Accuracy: 61.63%
Epoch [60/500], Step [2/2], Loss: 1.3212, Accuracy: 55.04%
Epoch [61/500], Step [2/2], Loss: 1.2033, Accuracy: 59.88%
Epoch [62/500], Step [2/2], Loss: 1.2676, Accuracy: 51.74%
Epoch [63/500], Step [2/2], Loss: 1.3088, Accuracy: 51.55%
Epoch [64/500], Step [2/2], Loss: 1.0972, Accuracy: 62.98%
Epoch [65/500], Step [2/2], Loss: 1.1751, Accuracy: 60.08%
Epoch [66/500], Step [2/2], Loss: 1.1973, Accuracy: 57.75%
Epoch [67/500], Step [2/2], Loss: 1.1762, Accuracy: 61.82%
Epoch [68/500], Step [2/2], Loss: 1.1484, Accuracy: 63.95%
Epoch [69/500], Step [2/2], Loss: 1.0804, Accuracy: 62.79%
Epoch [70/500], Step [2/2], Loss: 1.0947, Accuracy: 64.53%
Epoch [71/500], Step [2/2], Loss: 1.0838, Accuracy: 66.28%
Epoch [72/500], Step [2/2], Loss: 1.0590, Accuracy: 66.28%
Epoch [73/500], Step [2/2], Loss: 1.1062, Accuracy: 63.95%
Epoch [74/500], Step [2/2], Loss: 1.0365, Accuracy: 65.70%
Epoch [75/500], Step [2/2], Loss: 0.9977, Accuracy: 66.47%
Epoch [76/500], Step [2/2], Loss: 1.0100, Accuracy: 65.70%
Epoch [77/500], Step [2/2], Loss: 1.0648, Accuracy: 63.37%
Epoch [78/500], Step [2/2], Loss: 1.0576, Accuracy: 64.34%
Epoch [79/500], Step [2/2], Loss: 1.0457, Accuracy: 66.09%
Epoch [80/500], Step [2/2], Loss: 1.0312, Accuracy: 67.44%
Epoch [81/500], Step [2/2], Loss: 1.0098, Accuracy: 66.47%
Epoch [82/500], Step [2/2], Loss: 1.0930, Accuracy: 62.60%
Epoch [83/500], Step [2/2], Loss: 0.9778, Accuracy: 66.09%
Epoch [84/500], Step [2/2], Loss: 1.0925, Accuracy: 60.47%
Epoch [85/500], Step [2/2], Loss: 1.0504, Accuracy: 61.05%
Epoch [86/500], Step [2/2], Loss: 1.0889, Accuracy: 59.30%
Epoch [87/500], Step [2/2], Loss: 1.0335, Accuracy: 62.21%
Epoch [88/500], Step [2/2], Loss: 1.0210, Accuracy: 67.83%
Epoch [89/500], Step [2/2], Loss: 0.9210, Accuracy: 67.25%
Epoch [90/500], Step [2/2], Loss: 0.9757, Accuracy: 67.64%
Epoch [91/500], Step [2/2], Loss: 0.9815, Accuracy: 67.83%
Epoch [92/500], Step [2/2], Loss: 1.0108, Accuracy: 67.64%
Epoch [93/500], Step [2/2], Loss: 0.9163, Accuracy: 71.12%
Epoch [94/500], Step [2/2], Loss: 0.9181, Accuracy: 70.16%
Epoch [95/500], Step [2/2], Loss: 0.9351, Accuracy: 67.44%
Epoch [96/500], Step [2/2], Loss: 0.9156, Accuracy: 69.57%
Epoch [97/500], Step [2/2], Loss: 1.0767, Accuracy: 60.85%
Epoch [98/500], Step [2/2], Loss: 0.9501, Accuracy: 67.83%
Epoch [99/500], Step [2/2], Loss: 0.9496, Accuracy: 65.70%
Epoch [100/500], Step [2/2], Loss: 0.8844, Accuracy: 69.57%
Epoch [101/500], Step [2/2], Loss: 0.8983, Accuracy: 70.54%
Epoch [102/500], Step [2/2], Loss: 0.9371, Accuracy: 64.53%
Epoch [103/500], Step [2/2], Loss: 0.9688, Accuracy: 69.57%
Epoch [104/500], Step [2/2], Loss: 0.9506, Accuracy: 63.76%
Epoch [105/500], Step [2/2], Loss: 0.8525, Accuracy: 69.57%
Epoch [106/500], Step [2/2], Loss: 0.8675, Accuracy: 71.32%
Epoch [107/500], Step [2/2], Loss: 0.8764, Accuracy: 68.22%
Epoch [108/500], Step [2/2], Loss: 0.8728, Accuracy: 71.12%
Epoch [109/500], Step [2/2], Loss: 0.8751, Accuracy: 69.19%
Epoch [110/500], Step [2/2], Loss: 0.8517, Accuracy: 69.96%
Epoch [111/500], Step [2/2], Loss: 0.8383, Accuracy: 71.51%
Epoch [112/500], Step [2/2], Loss: 0.8522, Accuracy: 72.09%
Epoch [113/500], Step [2/2], Loss: 0.8915, Accuracy: 68.99%
Epoch [114/500], Step [2/2], Loss: 0.8231, Accuracy: 72.67%
Epoch [115/500], Step [2/2], Loss: 0.8220, Accuracy: 70.16%
Epoch [116/500], Step [2/2], Loss: 0.8336, Accuracy: 72.87%
Epoch [117/500], Step [2/2], Loss: 0.8836, Accuracy: 67.25%
Epoch [118/500], Step [2/2], Loss: 0.8790, Accuracy: 69.19%
Epoch [119/500], Step [2/2], Loss: 0.8176, Accuracy: 74.22%
Epoch [120/500], Step [2/2], Loss: 0.8574, Accuracy: 71.71%
Epoch [121/500], Step [2/2], Loss: 0.8382, Accuracy: 70.16%
Epoch [122/500], Step [2/2], Loss: 0.8001, Accuracy: 72.87%
Epoch [123/500], Step [2/2], Loss: 0.7668, Accuracy: 74.22%
Epoch [124/500], Step [2/2], Loss: 0.8219, Accuracy: 72.87%
Epoch [125/500], Step [2/2], Loss: 0.8392, Accuracy: 69.77%
Epoch [126/500], Step [2/2], Loss: 0.8146, Accuracy: 72.67%
Epoch [127/500], Step [2/2], Loss: 0.8131, Accuracy: 71.51%
Epoch [128/500], Step [2/2], Loss: 0.8263, Accuracy: 69.57%
Epoch [129/500], Step [2/2], Loss: 0.8202, Accuracy: 75.58%
Epoch [130/500], Step [2/2], Loss: 0.8170, Accuracy: 73.45%
Epoch [131/500], Step [2/2], Loss: 0.7794, Accuracy: 76.36%
Epoch [132/500], Step [2/2], Loss: 0.8471, Accuracy: 67.44%
Epoch [133/500], Step [2/2], Loss: 0.8260, Accuracy: 71.51%
Epoch [134/500], Step [2/2], Loss: 0.7581, Accuracy: 75.97%
Epoch [135/500], Step [2/2], Loss: 0.8623, Accuracy: 67.05%
Epoch [136/500], Step [2/2], Loss: 0.8726, Accuracy: 69.38%
Epoch [137/500], Step [2/2], Loss: 0.7654, Accuracy: 74.03%
Epoch [138/500], Step [2/2], Loss: 0.9349, Accuracy: 63.76%
Epoch [139/500], Step [2/2], Loss: 0.9243, Accuracy: 66.28%
Epoch [140/500], Step [2/2], Loss: 0.7803, Accuracy: 75.00%
Epoch [141/500], Step [2/2], Loss: 0.7904, Accuracy: 72.87%
Epoch [142/500], Step [2/2], Loss: 0.7827, Accuracy: 73.84%
Epoch [143/500], Step [2/2], Loss: 0.7642, Accuracy: 74.81%
Epoch [144/500], Step [2/2], Loss: 0.7615, Accuracy: 72.87%
Epoch [145/500], Step [2/2], Loss: 0.7593, Accuracy: 74.61%
Epoch [146/500], Step [2/2], Loss: 0.7770, Accuracy: 73.84%
Epoch [147/500], Step [2/2], Loss: 0.7431, Accuracy: 72.48%
Epoch [148/500], Step [2/2], Loss: 0.7739, Accuracy: 74.81%
Epoch [149/500], Step [2/2], Loss: 0.7908, Accuracy: 74.61%
Epoch [150/500], Step [2/2], Loss: 0.7529, Accuracy: 74.61%
Epoch [151/500], Step [2/2], Loss: 0.7109, Accuracy: 76.55%
Epoch [152/500], Step [2/2], Loss: 0.7516, Accuracy: 73.84%
Epoch [153/500], Step [2/2], Loss: 0.7357, Accuracy: 75.58%
Epoch [154/500], Step [2/2], Loss: 0.6920, Accuracy: 77.52%
Epoch [155/500], Step [2/2], Loss: 0.7652, Accuracy: 74.42%
Epoch [156/500], Step [2/2], Loss: 0.7020, Accuracy: 78.10%
Epoch [157/500], Step [2/2], Loss: 0.7234, Accuracy: 74.61%
Epoch [158/500], Step [2/2], Loss: 0.7791, Accuracy: 76.16%
Epoch [159/500], Step [2/2], Loss: 0.7877, Accuracy: 70.54%
Epoch [160/500], Step [2/2], Loss: 0.7267, Accuracy: 76.94%
Epoch [161/500], Step [2/2], Loss: 0.6925, Accuracy: 78.68%
Epoch [162/500], Step [2/2], Loss: 0.7649, Accuracy: 70.35%
Epoch [163/500], Step [2/2], Loss: 0.7792, Accuracy: 75.78%
Epoch [164/500], Step [2/2], Loss: 0.7209, Accuracy: 73.84%
Epoch [165/500], Step [2/2], Loss: 0.7057, Accuracy: 75.97%
Epoch [166/500], Step [2/2], Loss: 0.7100, Accuracy: 76.74%
Epoch [167/500], Step [2/2], Loss: 0.6955, Accuracy: 73.26%
Epoch [168/500], Step [2/2], Loss: 0.7217, Accuracy: 75.58%
Epoch [169/500], Step [2/2], Loss: 0.6656, Accuracy: 77.71%
Epoch [170/500], Step [2/2], Loss: 0.6682, Accuracy: 79.46%
Epoch [171/500], Step [2/2], Loss: 0.6882, Accuracy: 76.55%
Epoch [172/500], Step [2/2], Loss: 0.6743, Accuracy: 75.00%
Epoch [173/500], Step [2/2], Loss: 0.6588, Accuracy: 75.58%
Epoch [174/500], Step [2/2], Loss: 0.6985, Accuracy: 75.97%
Epoch [175/500], Step [2/2], Loss: 0.6879, Accuracy: 75.39%
Epoch [176/500], Step [2/2], Loss: 0.6602, Accuracy: 78.10%
Epoch [177/500], Step [2/2], Loss: 0.7092, Accuracy: 76.16%
Epoch [178/500], Step [2/2], Loss: 0.6650, Accuracy: 75.58%
Epoch [179/500], Step [2/2], Loss: 0.6688, Accuracy: 77.91%
Epoch [180/500], Step [2/2], Loss: 0.6879, Accuracy: 78.49%
Epoch [181/500], Step [2/2], Loss: 0.7215, Accuracy: 74.81%
Epoch [182/500], Step [2/2], Loss: 0.7801, Accuracy: 69.77%
Epoch [183/500], Step [2/2], Loss: 0.7085, Accuracy: 77.52%
Epoch [184/500], Step [2/2], Loss: 0.6626, Accuracy: 71.90%
Epoch [185/500], Step [2/2], Loss: 0.6769, Accuracy: 75.97%
Epoch [186/500], Step [2/2], Loss: 0.6914, Accuracy: 77.71%
Epoch [187/500], Step [2/2], Loss: 0.6517, Accuracy: 75.58%
Epoch [188/500], Step [2/2], Loss: 0.6490, Accuracy: 78.10%
Epoch [189/500], Step [2/2], Loss: 0.6471, Accuracy: 76.94%
Epoch [190/500], Step [2/2], Loss: 0.7007, Accuracy: 75.19%
Epoch [191/500], Step [2/2], Loss: 0.6761, Accuracy: 78.10%
Epoch [192/500], Step [2/2], Loss: 0.6394, Accuracy: 76.55%
Epoch [193/500], Step [2/2], Loss: 0.6061, Accuracy: 79.46%
Epoch [194/500], Step [2/2], Loss: 0.6560, Accuracy: 77.52%
Epoch [195/500], Step [2/2], Loss: 0.6678, Accuracy: 75.39%
Epoch [196/500], Step [2/2], Loss: 0.7075, Accuracy: 73.64%
Epoch [197/500], Step [2/2], Loss: 0.6375, Accuracy: 77.33%
Epoch [198/500], Step [2/2], Loss: 0.6252, Accuracy: 77.71%
Epoch [199/500], Step [2/2], Loss: 0.6301, Accuracy: 78.10%
Epoch [200/500], Step [2/2], Loss: 0.6598, Accuracy: 76.16%
Epoch [201/500], Step [2/2], Loss: 0.7215, Accuracy: 77.71%
Epoch [202/500], Step [2/2], Loss: 0.6085, Accuracy: 78.68%
Epoch [203/500], Step [2/2], Loss: 0.6330, Accuracy: 76.94%
Epoch [204/500], Step [2/2], Loss: 0.6420, Accuracy: 78.29%
Epoch [205/500], Step [2/2], Loss: 0.6090, Accuracy: 79.26%
Epoch [206/500], Step [2/2], Loss: 0.5939, Accuracy: 79.84%
Epoch [207/500], Step [2/2], Loss: 0.5947, Accuracy: 81.20%
Epoch [208/500], Step [2/2], Loss: 0.6490, Accuracy: 76.74%
Epoch [209/500], Step [2/2], Loss: 0.6450, Accuracy: 75.39%
Epoch [210/500], Step [2/2], Loss: 0.6323, Accuracy: 80.23%
Epoch [211/500], Step [2/2], Loss: 0.6000, Accuracy: 77.91%
Epoch [212/500], Step [2/2], Loss: 0.6446, Accuracy: 76.94%
Epoch [213/500], Step [2/2], Loss: 0.6000, Accuracy: 82.36%
Epoch [214/500], Step [2/2], Loss: 0.5867, Accuracy: 80.04%
Epoch [215/500], Step [2/2], Loss: 0.6263, Accuracy: 79.46%
Epoch [216/500], Step [2/2], Loss: 0.6264, Accuracy: 80.62%
Epoch [217/500], Step [2/2], Loss: 0.6488, Accuracy: 74.22%
Epoch [218/500], Step [2/2], Loss: 0.6448, Accuracy: 79.26%
Epoch [219/500], Step [2/2], Loss: 0.6051, Accuracy: 78.49%
Epoch [220/500], Step [2/2], Loss: 0.6479, Accuracy: 77.52%
Epoch [221/500], Step [2/2], Loss: 0.6720, Accuracy: 77.13%
Epoch [222/500], Step [2/2], Loss: 0.6750, Accuracy: 74.42%
Epoch [223/500], Step [2/2], Loss: 0.6296, Accuracy: 80.04%
Epoch [224/500], Step [2/2], Loss: 0.6161, Accuracy: 78.88%
Epoch [225/500], Step [2/2], Loss: 0.6619, Accuracy: 76.55%
Epoch [226/500], Step [2/2], Loss: 0.5938, Accuracy: 80.04%
Epoch [227/500], Step [2/2], Loss: 0.6684, Accuracy: 77.33%
Epoch [228/500], Step [2/2], Loss: 0.6633, Accuracy: 76.55%
Epoch [229/500], Step [2/2], Loss: 0.6071, Accuracy: 78.68%
Epoch [230/500], Step [2/2], Loss: 0.5665, Accuracy: 81.78%
Epoch [231/500], Step [2/2], Loss: 0.6494, Accuracy: 79.26%
Epoch [232/500], Step [2/2], Loss: 0.5788, Accuracy: 80.04%
Epoch [233/500], Step [2/2], Loss: 0.5909, Accuracy: 78.10%
Epoch [234/500], Step [2/2], Loss: 0.5784, Accuracy: 76.94%
Epoch [235/500], Step [2/2], Loss: 0.6119, Accuracy: 78.88%
Epoch [236/500], Step [2/2], Loss: 0.5528, Accuracy: 80.23%
Epoch [237/500], Step [2/2], Loss: 0.6209, Accuracy: 78.88%
Epoch [238/500], Step [2/2], Loss: 0.5762, Accuracy: 80.23%
Epoch [239/500], Step [2/2], Loss: 0.5702, Accuracy: 80.43%
Epoch [240/500], Step [2/2], Loss: 0.5805, Accuracy: 80.04%
Epoch [241/500], Step [2/2], Loss: 0.5816, Accuracy: 82.36%
Epoch [242/500], Step [2/2], Loss: 0.5782, Accuracy: 77.52%
Epoch [243/500], Step [2/2], Loss: 0.5899, Accuracy: 78.49%
Epoch [244/500], Step [2/2], Loss: 0.5610, Accuracy: 79.65%
Epoch [245/500], Step [2/2], Loss: 0.5531, Accuracy: 79.65%
Epoch [246/500], Step [2/2], Loss: 0.5845, Accuracy: 79.65%
Epoch [247/500], Step [2/2], Loss: 0.5322, Accuracy: 81.78%
Epoch [248/500], Step [2/2], Loss: 0.5897, Accuracy: 81.98%
Epoch [249/500], Step [2/2], Loss: 0.5633, Accuracy: 80.23%
Epoch [250/500], Step [2/2], Loss: 0.5583, Accuracy: 79.65%
Epoch [251/500], Step [2/2], Loss: 0.5127, Accuracy: 82.56%
Epoch [252/500], Step [2/2], Loss: 0.5419, Accuracy: 80.62%
Epoch [253/500], Step [2/2], Loss: 0.5557, Accuracy: 79.46%
Epoch [254/500], Step [2/2], Loss: 0.5849, Accuracy: 77.91%
Epoch [255/500], Step [2/2], Loss: 0.5767, Accuracy: 80.23%
Epoch [256/500], Step [2/2], Loss: 0.5337, Accuracy: 82.36%
Epoch [257/500], Step [2/2], Loss: 0.5712, Accuracy: 78.88%
Epoch [258/500], Step [2/2], Loss: 0.5329, Accuracy: 80.62%
Epoch [259/500], Step [2/2], Loss: 0.5663, Accuracy: 77.91%
Epoch [260/500], Step [2/2], Loss: 0.5672, Accuracy: 78.68%
Epoch [261/500], Step [2/2], Loss: 0.5890, Accuracy: 78.88%
Epoch [262/500], Step [2/2], Loss: 0.5079, Accuracy: 83.14%
Epoch [263/500], Step [2/2], Loss: 0.5703, Accuracy: 79.46%
Epoch [264/500], Step [2/2], Loss: 0.5971, Accuracy: 79.26%
Epoch [265/500], Step [2/2], Loss: 0.5210, Accuracy: 81.40%
Epoch [266/500], Step [2/2], Loss: 0.5359, Accuracy: 81.40%
Epoch [267/500], Step [2/2], Loss: 0.6050, Accuracy: 79.46%
Epoch [268/500], Step [2/2], Loss: 0.5556, Accuracy: 79.84%
Epoch [269/500], Step [2/2], Loss: 0.5265, Accuracy: 79.65%
Epoch [270/500], Step [2/2], Loss: 0.5694, Accuracy: 80.23%
Epoch [271/500], Step [2/2], Loss: 0.6224, Accuracy: 79.46%
Epoch [272/500], Step [2/2], Loss: 0.6277, Accuracy: 76.74%
Epoch [273/500], Step [2/2], Loss: 0.6119, Accuracy: 78.49%
Epoch [274/500], Step [2/2], Loss: 0.5442, Accuracy: 82.56%
Epoch [275/500], Step [2/2], Loss: 0.5458, Accuracy: 81.98%
Epoch [276/500], Step [2/2], Loss: 0.6778, Accuracy: 76.16%
Epoch [277/500], Step [2/2], Loss: 0.6326, Accuracy: 77.33%
Epoch [278/500], Step [2/2], Loss: 0.5553, Accuracy: 81.78%
Epoch [279/500], Step [2/2], Loss: 0.5721, Accuracy: 79.26%
Epoch [280/500], Step [2/2], Loss: 0.5111, Accuracy: 82.95%
Epoch [281/500], Step [2/2], Loss: 0.5541, Accuracy: 79.84%
Epoch [282/500], Step [2/2], Loss: 0.5306, Accuracy: 81.20%
Epoch [283/500], Step [2/2], Loss: 0.5277, Accuracy: 80.81%
Epoch [284/500], Step [2/2], Loss: 0.5256, Accuracy: 81.59%
Epoch [285/500], Step [2/2], Loss: 0.5088, Accuracy: 83.53%
Epoch [286/500], Step [2/2], Loss: 0.4997, Accuracy: 82.36%
Epoch [287/500], Step [2/2], Loss: 0.6085, Accuracy: 77.13%
Epoch [288/500], Step [2/2], Loss: 0.5545, Accuracy: 82.56%
Epoch [289/500], Step [2/2], Loss: 0.4790, Accuracy: 82.56%
Epoch [290/500], Step [2/2], Loss: 0.5356, Accuracy: 80.43%
Epoch [291/500], Step [2/2], Loss: 0.5778, Accuracy: 77.91%
Epoch [292/500], Step [2/2], Loss: 0.5581, Accuracy: 79.07%
Epoch [293/500], Step [2/2], Loss: 0.5128, Accuracy: 81.98%
Epoch [294/500], Step [2/2], Loss: 0.4900, Accuracy: 82.95%
Epoch [295/500], Step [2/2], Loss: 0.4844, Accuracy: 82.95%
Epoch [296/500], Step [2/2], Loss: 0.4924, Accuracy: 84.30%
Epoch [297/500], Step [2/2], Loss: 0.4752, Accuracy: 81.40%
Epoch [298/500], Step [2/2], Loss: 0.4698, Accuracy: 83.33%
Epoch [299/500], Step [2/2], Loss: 0.4863, Accuracy: 84.30%
Epoch [300/500], Step [2/2], Loss: 0.5101, Accuracy: 83.14%
Epoch [301/500], Step [2/2], Loss: 0.4945, Accuracy: 83.72%
Epoch [302/500], Step [2/2], Loss: 0.5212, Accuracy: 81.20%
Epoch [303/500], Step [2/2], Loss: 0.4856, Accuracy: 81.40%
Epoch [304/500], Step [2/2], Loss: 0.4994, Accuracy: 83.14%
Epoch [305/500], Step [2/2], Loss: 0.4723, Accuracy: 82.75%
Epoch [306/500], Step [2/2], Loss: 0.5147, Accuracy: 81.20%
Epoch [307/500], Step [2/2], Loss: 0.4908, Accuracy: 83.53%
Epoch [308/500], Step [2/2], Loss: 0.5049, Accuracy: 80.81%
Epoch [309/500], Step [2/2], Loss: 0.4595, Accuracy: 85.08%
Epoch [310/500], Step [2/2], Loss: 0.4724, Accuracy: 81.78%
Epoch [311/500], Step [2/2], Loss: 0.5018, Accuracy: 82.56%
Epoch [312/500], Step [2/2], Loss: 0.4983, Accuracy: 83.14%
Epoch [313/500], Step [2/2], Loss: 0.4737, Accuracy: 82.56%
Epoch [314/500], Step [2/2], Loss: 0.4700, Accuracy: 85.08%
Epoch [315/500], Step [2/2], Loss: 0.4689, Accuracy: 84.11%
Epoch [316/500], Step [2/2], Loss: 0.4581, Accuracy: 83.72%
Epoch [317/500], Step [2/2], Loss: 0.4906, Accuracy: 79.65%
Epoch [318/500], Step [2/2], Loss: 0.5172, Accuracy: 81.98%
Epoch [319/500], Step [2/2], Loss: 0.5476, Accuracy: 78.49%
Epoch [320/500], Step [2/2], Loss: 0.5492, Accuracy: 79.26%
Epoch [321/500], Step [2/2], Loss: 0.4584, Accuracy: 83.53%
Epoch [322/500], Step [2/2], Loss: 0.4910, Accuracy: 82.56%
Epoch [323/500], Step [2/2], Loss: 0.5296, Accuracy: 81.78%
Epoch [324/500], Step [2/2], Loss: 0.4603, Accuracy: 83.91%
Epoch [325/500], Step [2/2], Loss: 0.4930, Accuracy: 82.75%
Epoch [326/500], Step [2/2], Loss: 0.4391, Accuracy: 83.14%
Epoch [327/500], Step [2/2], Loss: 0.4791, Accuracy: 84.11%
Epoch [328/500], Step [2/2], Loss: 0.4459, Accuracy: 82.75%
Epoch [329/500], Step [2/2], Loss: 0.4816, Accuracy: 82.17%
Epoch [330/500], Step [2/2], Loss: 0.4915, Accuracy: 81.59%
Epoch [331/500], Step [2/2], Loss: 0.4925, Accuracy: 83.91%
Epoch [332/500], Step [2/2], Loss: 0.4899, Accuracy: 81.20%
Epoch [333/500], Step [2/2], Loss: 0.5495, Accuracy: 81.78%
Epoch [334/500], Step [2/2], Loss: 0.4968, Accuracy: 81.78%
Epoch [335/500], Step [2/2], Loss: 0.4763, Accuracy: 84.50%
Epoch [336/500], Step [2/2], Loss: 0.4458, Accuracy: 83.91%
Epoch [337/500], Step [2/2], Loss: 0.4533, Accuracy: 84.11%
Epoch [338/500], Step [2/2], Loss: 0.4646, Accuracy: 84.50%
Epoch [339/500], Step [2/2], Loss: 0.4725, Accuracy: 83.72%
Epoch [340/500], Step [2/2], Loss: 0.4377, Accuracy: 85.08%
Epoch [341/500], Step [2/2], Loss: 0.4546, Accuracy: 82.75%
Epoch [342/500], Step [2/2], Loss: 0.4818, Accuracy: 83.53%
Epoch [343/500], Step [2/2], Loss: 0.4925, Accuracy: 81.98%
Epoch [344/500], Step [2/2], Loss: 0.4234, Accuracy: 86.05%
Epoch [345/500], Step [2/2], Loss: 0.4228, Accuracy: 86.63%
Epoch [346/500], Step [2/2], Loss: 0.4711, Accuracy: 83.91%
Epoch [347/500], Step [2/2], Loss: 0.4204, Accuracy: 86.24%
Epoch [348/500], Step [2/2], Loss: 0.3838, Accuracy: 86.63%
Epoch [349/500], Step [2/2], Loss: 0.4650, Accuracy: 82.17%
Epoch [350/500], Step [2/2], Loss: 0.4618, Accuracy: 83.14%
Epoch [351/500], Step [2/2], Loss: 0.4811, Accuracy: 83.14%
Epoch [352/500], Step [2/2], Loss: 0.5403, Accuracy: 79.84%
Epoch [353/500], Step [2/2], Loss: 0.4697, Accuracy: 84.88%
Epoch [354/500], Step [2/2], Loss: 0.4681, Accuracy: 83.14%
Epoch [355/500], Step [2/2], Loss: 0.4854, Accuracy: 83.33%
Epoch [356/500], Step [2/2], Loss: 0.4954, Accuracy: 80.81%
Epoch [357/500], Step [2/2], Loss: 0.4711, Accuracy: 82.95%
Epoch [358/500], Step [2/2], Loss: 0.4701, Accuracy: 84.11%
Epoch [359/500], Step [2/2], Loss: 0.4848, Accuracy: 82.95%
Epoch [360/500], Step [2/2], Loss: 0.4119, Accuracy: 86.63%
Epoch [361/500], Step [2/2], Loss: 0.4437, Accuracy: 84.50%
Epoch [362/500], Step [2/2], Loss: 0.6101, Accuracy: 76.94%
Epoch [363/500], Step [2/2], Loss: 0.5117, Accuracy: 81.40%
Epoch [364/500], Step [2/2], Loss: 0.4906, Accuracy: 83.14%
Epoch [365/500], Step [2/2], Loss: 0.4185, Accuracy: 84.69%
Epoch [366/500], Step [2/2], Loss: 0.4276, Accuracy: 87.02%
Epoch [367/500], Step [2/2], Loss: 0.4590, Accuracy: 82.75%
Epoch [368/500], Step [2/2], Loss: 0.4356, Accuracy: 84.11%
Epoch [369/500], Step [2/2], Loss: 0.4463, Accuracy: 84.50%
Epoch [370/500], Step [2/2], Loss: 0.4315, Accuracy: 84.50%
Epoch [371/500], Step [2/2], Loss: 0.3900, Accuracy: 86.82%
Epoch [372/500], Step [2/2], Loss: 0.4702, Accuracy: 82.75%
Epoch [373/500], Step [2/2], Loss: 0.4496, Accuracy: 82.56%
Epoch [374/500], Step [2/2], Loss: 0.4095, Accuracy: 86.24%
Epoch [375/500], Step [2/2], Loss: 0.4208, Accuracy: 84.11%
Epoch [376/500], Step [2/2], Loss: 0.4393, Accuracy: 84.11%
Epoch [377/500], Step [2/2], Loss: 0.4094, Accuracy: 86.05%
Epoch [378/500], Step [2/2], Loss: 0.4159, Accuracy: 85.85%
Epoch [379/500], Step [2/2], Loss: 0.4704, Accuracy: 84.11%
Epoch [380/500], Step [2/2], Loss: 0.4365, Accuracy: 85.08%
Epoch [381/500], Step [2/2], Loss: 0.4548, Accuracy: 85.08%
Epoch [382/500], Step [2/2], Loss: 0.4393, Accuracy: 84.11%
Epoch [383/500], Step [2/2], Loss: 0.3578, Accuracy: 86.82%
Epoch [384/500], Step [2/2], Loss: 0.4612, Accuracy: 82.75%
Epoch [385/500], Step [2/2], Loss: 0.4044, Accuracy: 85.85%
Epoch [386/500], Step [2/2], Loss: 0.4053, Accuracy: 84.50%
Epoch [387/500], Step [2/2], Loss: 0.3736, Accuracy: 88.37%
Epoch [388/500], Step [2/2], Loss: 0.3965, Accuracy: 87.02%
Epoch [389/500], Step [2/2], Loss: 0.4511, Accuracy: 84.11%
Epoch [390/500], Step [2/2], Loss: 0.4032, Accuracy: 85.47%
Epoch [391/500], Step [2/2], Loss: 0.3920, Accuracy: 86.05%
Epoch [392/500], Step [2/2], Loss: 0.4124, Accuracy: 87.21%
Epoch [393/500], Step [2/2], Loss: 0.4301, Accuracy: 86.43%
Epoch [394/500], Step [2/2], Loss: 0.3881, Accuracy: 86.82%
Epoch [395/500], Step [2/2], Loss: 0.3693, Accuracy: 87.98%
Epoch [396/500], Step [2/2], Loss: 0.4177, Accuracy: 87.60%
Epoch [397/500], Step [2/2], Loss: 0.4493, Accuracy: 80.62%
Epoch [398/500], Step [2/2], Loss: 0.4166, Accuracy: 86.24%
Epoch [399/500], Step [2/2], Loss: 0.4035, Accuracy: 86.05%
Epoch [400/500], Step [2/2], Loss: 0.4187, Accuracy: 86.82%
Epoch [401/500], Step [2/2], Loss: 0.4539, Accuracy: 83.33%
Epoch [402/500], Step [2/2], Loss: 0.3790, Accuracy: 87.79%
Epoch [403/500], Step [2/2], Loss: 0.3786, Accuracy: 87.60%
Epoch [404/500], Step [2/2], Loss: 0.4461, Accuracy: 84.11%
Epoch [405/500], Step [2/2], Loss: 0.4071, Accuracy: 86.82%
Epoch [406/500], Step [2/2], Loss: 0.4221, Accuracy: 85.27%
Epoch [407/500], Step [2/2], Loss: 0.3937, Accuracy: 86.05%
Epoch [408/500], Step [2/2], Loss: 0.3647, Accuracy: 87.79%
Epoch [409/500], Step [2/2], Loss: 0.4304, Accuracy: 83.33%
Epoch [410/500], Step [2/2], Loss: 0.3711, Accuracy: 85.47%
Epoch [411/500], Step [2/2], Loss: 0.3835, Accuracy: 88.76%
Epoch [412/500], Step [2/2], Loss: 0.4056, Accuracy: 86.24%
Epoch [413/500], Step [2/2], Loss: 0.3763, Accuracy: 87.02%
Epoch [414/500], Step [2/2], Loss: 0.4192, Accuracy: 86.63%
Epoch [415/500], Step [2/2], Loss: 0.4781, Accuracy: 81.98%
Epoch [416/500], Step [2/2], Loss: 0.5223, Accuracy: 81.59%
Epoch [417/500], Step [2/2], Loss: 0.4583, Accuracy: 83.53%
Epoch [418/500], Step [2/2], Loss: 0.4312, Accuracy: 85.27%
Epoch [419/500], Step [2/2], Loss: 0.4302, Accuracy: 85.27%
Epoch [420/500], Step [2/2], Loss: 0.3977, Accuracy: 86.05%
Epoch [421/500], Step [2/2], Loss: 0.3988, Accuracy: 87.02%
Epoch [422/500], Step [2/2], Loss: 0.3833, Accuracy: 85.85%
Epoch [423/500], Step [2/2], Loss: 0.3327, Accuracy: 89.73%
Epoch [424/500], Step [2/2], Loss: 0.3301, Accuracy: 88.57%
Epoch [425/500], Step [2/2], Loss: 0.3661, Accuracy: 87.40%
Epoch [426/500], Step [2/2], Loss: 0.4200, Accuracy: 87.60%
Epoch [427/500], Step [2/2], Loss: 0.3934, Accuracy: 84.30%
Epoch [428/500], Step [2/2], Loss: 0.3716, Accuracy: 88.18%
Epoch [429/500], Step [2/2], Loss: 0.4209, Accuracy: 85.47%
Epoch [430/500], Step [2/2], Loss: 0.4527, Accuracy: 83.72%
Epoch [431/500], Step [2/2], Loss: 0.4126, Accuracy: 84.50%
Epoch [432/500], Step [2/2], Loss: 0.3869, Accuracy: 87.40%
Epoch [433/500], Step [2/2], Loss: 0.4158, Accuracy: 84.69%
Epoch [434/500], Step [2/2], Loss: 0.4271, Accuracy: 84.30%
Epoch [435/500], Step [2/2], Loss: 0.4178, Accuracy: 86.05%
Epoch [436/500], Step [2/2], Loss: 0.4090, Accuracy: 85.08%
Epoch [437/500], Step [2/2], Loss: 0.3602, Accuracy: 87.79%
Epoch [438/500], Step [2/2], Loss: 0.3990, Accuracy: 86.05%
Epoch [439/500], Step [2/2], Loss: 0.3593, Accuracy: 87.60%
Epoch [440/500], Step [2/2], Loss: 0.3876, Accuracy: 86.05%
Epoch [441/500], Step [2/2], Loss: 0.4190, Accuracy: 83.72%
Epoch [442/500], Step [2/2], Loss: 0.4213, Accuracy: 85.27%
Epoch [443/500], Step [2/2], Loss: 0.4259, Accuracy: 85.27%
Epoch [444/500], Step [2/2], Loss: 0.5861, Accuracy: 78.49%
Epoch [445/500], Step [2/2], Loss: 0.6347, Accuracy: 78.68%
Epoch [446/500], Step [2/2], Loss: 0.6207, Accuracy: 75.39%
Epoch [447/500], Step [2/2], Loss: 0.6460, Accuracy: 75.78%
Epoch [448/500], Step [2/2], Loss: 0.5575, Accuracy: 79.26%
Epoch [449/500], Step [2/2], Loss: 0.4406, Accuracy: 84.88%
Epoch [450/500], Step [2/2], Loss: 0.3529, Accuracy: 89.73%
Epoch [451/500], Step [2/2], Loss: 0.5433, Accuracy: 81.01%
Epoch [452/500], Step [2/2], Loss: 0.4060, Accuracy: 86.63%
Epoch [453/500], Step [2/2], Loss: 0.4172, Accuracy: 84.11%
Epoch [454/500], Step [2/2], Loss: 0.4332, Accuracy: 84.88%
Epoch [455/500], Step [2/2], Loss: 0.4398, Accuracy: 85.27%
Epoch [456/500], Step [2/2], Loss: 0.4115, Accuracy: 84.69%
Epoch [457/500], Step [2/2], Loss: 0.3539, Accuracy: 86.63%
Epoch [458/500], Step [2/2], Loss: 0.3819, Accuracy: 87.40%
Epoch [459/500], Step [2/2], Loss: 0.4289, Accuracy: 84.69%
Epoch [460/500], Step [2/2], Loss: 0.4076, Accuracy: 86.43%
Epoch [461/500], Step [2/2], Loss: 0.3649, Accuracy: 86.05%
Epoch [462/500], Step [2/2], Loss: 0.3543, Accuracy: 86.05%
Epoch [463/500], Step [2/2], Loss: 0.3556, Accuracy: 88.95%
Epoch [464/500], Step [2/2], Loss: 0.3174, Accuracy: 89.73%
Epoch [465/500], Step [2/2], Loss: 0.3363, Accuracy: 87.98%
Epoch [466/500], Step [2/2], Loss: 0.3272, Accuracy: 89.73%
Epoch [467/500], Step [2/2], Loss: 0.3686, Accuracy: 86.82%
Epoch [468/500], Step [2/2], Loss: 0.4003, Accuracy: 86.05%
Epoch [469/500], Step [2/2], Loss: 0.3444, Accuracy: 87.40%
Epoch [470/500], Step [2/2], Loss: 0.3610, Accuracy: 87.60%
Epoch [471/500], Step [2/2], Loss: 0.4023, Accuracy: 84.69%
Epoch [472/500], Step [2/2], Loss: 0.3787, Accuracy: 87.98%
Epoch [473/500], Step [2/2], Loss: 0.3519, Accuracy: 88.95%
Epoch [474/500], Step [2/2], Loss: 0.4116, Accuracy: 85.66%
Epoch [475/500], Step [2/2], Loss: 0.3498, Accuracy: 87.98%
Epoch [476/500], Step [2/2], Loss: 0.3133, Accuracy: 88.57%
Epoch [477/500], Step [2/2], Loss: 0.3183, Accuracy: 89.53%
Epoch [478/500], Step [2/2], Loss: 0.3402, Accuracy: 89.73%
Epoch [479/500], Step [2/2], Loss: 0.3612, Accuracy: 87.21%
Epoch [480/500], Step [2/2], Loss: 0.3296, Accuracy: 89.34%
Epoch [481/500], Step [2/2], Loss: 0.3438, Accuracy: 86.82%
Epoch [482/500], Step [2/2], Loss: 0.4223, Accuracy: 83.72%
Epoch [483/500], Step [2/2], Loss: 0.5133, Accuracy: 80.62%
Epoch [484/500], Step [2/2], Loss: 0.4169, Accuracy: 85.27%
Epoch [485/500], Step [2/2], Loss: 0.3991, Accuracy: 85.27%
Epoch [486/500], Step [2/2], Loss: 0.3774, Accuracy: 87.21%
Epoch [487/500], Step [2/2], Loss: 0.3712, Accuracy: 87.21%
Epoch [488/500], Step [2/2], Loss: 0.3347, Accuracy: 88.37%
Epoch [489/500], Step [2/2], Loss: 0.2993, Accuracy: 90.50%
Epoch [490/500], Step [2/2], Loss: 0.3779, Accuracy: 87.60%
Epoch [491/500], Step [2/2], Loss: 0.3482, Accuracy: 87.21%
Epoch [492/500], Step [2/2], Loss: 0.4319, Accuracy: 82.56%
Epoch [493/500], Step [2/2], Loss: 0.4371, Accuracy: 84.30%
Epoch [494/500], Step [2/2], Loss: 0.5015, Accuracy: 78.88%
Epoch [495/500], Step [2/2], Loss: 0.5359, Accuracy: 78.49%
Epoch [496/500], Step [2/2], Loss: 0.5154, Accuracy: 80.81%
Epoch [497/500], Step [2/2], Loss: 0.3590, Accuracy: 88.18%
Epoch [498/500], Step [2/2], Loss: 0.3665, Accuracy: 87.40%
Epoch [499/500], Step [2/2], Loss: 0.3373, Accuracy: 86.63%
Epoch [500/500], Step [2/2], Loss: 0.3432, Accuracy: 88.76%
</pre></div>
</div>
</div>
</div>
<p>The training accuracy usually starts out below <span class="math notranslate nohighlight">\(10\%\)</span>, which makes sense as chance <span class="math notranslate nohighlight">\(100/14 \approx 7\%\)</span>. It usually quickly goes up to around <span class="math notranslate nohighlight">\(80\%\)</span>. The model can get better if you run more epochs, but this is sufficient for now.</p>
<p>Now we want to see performance on the test data set:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Test the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">real_labels</span><span class="p">,</span> <span class="n">predicted_labels</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">motions</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
    <span class="n">motions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">motions</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">real_labels</span> <span class="o">+=</span> <span class="nb">list</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">motions</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">predicted_labels</span> <span class="o">+=</span> <span class="nb">list</span><span class="p">(</span><span class="n">predicted</span><span class="p">)</span>
    <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test Accuracy of the model on the 172 test moves: </span><span class="si">{</span><span class="p">(</span><span class="n">correct</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test Accuracy of the model on the 172 test moves: 80.814%
</pre></div>
</div>
</div>
</div>
<p>Considering that we have a relatively small data set, and a fairly simple model that didn’t really converge, this is decent performance (chance is ~7%). Let’s look at where the errors are:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plt.style.use(&#39;dark_background&#39;)  # uncomment if you&#39;re using dark mode...</span>
<span class="n">plotConfusionMatrix</span><span class="p">(</span><span class="n">real_labels</span><span class="p">,</span> <span class="n">predicted_labels</span><span class="p">,</span> <span class="n">label_names</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/Example_Deep_Learning_Project_49_0.png" src="../../_images/Example_Deep_Learning_Project_49_0.png" />
</div>
</div>
<p>The errors vary each time the model is run, but a common error seems to be that head scratching is predicted from some other movements that also involve arms a lot: throw/catch, hand clapping, phone talking, checking watch, hand waving, taking photo. If we train the model longer, these errors tend to go away as well. For some reason, crossed legged sitting is sometimes misclassified for crawling, but this doesn’t always happen.</p>
</div>
</div>
<hr class="docutils" />
<div class="section" id="step-8-modeling-completion">
<h1>Step 8: Modeling completion<a class="headerlink" href="#step-8-modeling-completion" title="Permalink to this headline">¶</a></h1>
<p>Are we done yet? In order to answer our questions, reach our goals and evaluate our hypotheses we need to be able to get test performance from the model, and might want to investigate any errors that the model makes. We will first make a function that fits the model on a specified set of joints</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">testJointModel</span><span class="p">(</span><span class="n">joints</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">24</span><span class="p">)),</span>
                   <span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span>
                   <span class="n">batch_size</span><span class="o">=</span><span class="mi">516</span><span class="p">,</span>
                   <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">):</span>

  <span class="c1"># Hyperparameters</span>
  <span class="n">num_classes</span> <span class="o">=</span> <span class="mi">14</span>
  
  <span class="c1"># Create training and test datasets</span>
  <span class="n">movi_train</span> <span class="o">=</span> <span class="n">MoViJointDataset</span><span class="p">(</span><span class="n">train</span>  <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">joints</span> <span class="o">=</span> <span class="n">joints</span><span class="p">)</span>
  <span class="n">movi_test</span>  <span class="o">=</span> <span class="n">MoViJointDataset</span><span class="p">(</span><span class="n">train</span>  <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">joints</span> <span class="o">=</span> <span class="n">joints</span><span class="p">)</span>

  <span class="c1"># Data loaders</span>
  <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">movi_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="n">test_loader</span>  <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">movi_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>  <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

  <span class="c1"># create the model object:</span>
  <span class="n">model</span> <span class="o">=</span> <span class="n">Mov1DCNN</span><span class="p">(</span><span class="n">njoints</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">joints</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

  <span class="c1"># loss and optimizer:</span>
  <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
  <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

  <span class="c1"># Train the model</span>
  <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">motions</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
      <span class="n">motions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">motions</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

      <span class="c1"># Run the forward pass</span>
      <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">motions</span><span class="p">)</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
      <span class="n">loss_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

      <span class="c1"># Backprop and perform Adam optimisation</span>
      <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
      <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
      <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

      <span class="c1"># Track the accuracy</span>
      <span class="n">total</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
  
  <span class="c1"># Test the model</span>
  <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
  <span class="n">real_labels</span><span class="p">,</span> <span class="n">predicted_labels</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">motions</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
      <span class="n">motions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">motions</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
      <span class="n">real_labels</span> <span class="o">+=</span> <span class="nb">list</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
      <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">motions</span><span class="p">)</span>
      <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
      <span class="n">predicted_labels</span> <span class="o">+=</span> <span class="nb">list</span><span class="p">(</span><span class="n">predicted</span><span class="p">)</span>
      <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
      <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

  <span class="n">performance</span> <span class="o">=</span> <span class="p">(</span><span class="n">correct</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>

  <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;performance&#39;</span><span class="p">:</span> <span class="n">performance</span><span class="p">,</span>
          <span class="s1">&#39;real_labels&#39;</span><span class="p">:</span> <span class="n">real_labels</span><span class="p">,</span>
          <span class="s1">&#39;predicted_labels&#39;</span><span class="p">:</span> <span class="n">predicted_labels</span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s test this on a few select joints:</p>
<p><strong>This takes up to ~10 seconds:</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cnn6j</span> <span class="o">=</span> <span class="n">testJointModel</span><span class="p">(</span><span class="n">joints</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">23</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cnn6j</span><span class="p">[</span><span class="s1">&#39;performance&#39;</span><span class="p">])</span>
<span class="n">plotConfusionMatrix</span><span class="p">(</span><span class="n">real_labels</span> <span class="o">=</span> <span class="n">cnn6j</span><span class="p">[</span><span class="s1">&#39;real_labels&#39;</span><span class="p">],</span> <span class="n">predicted_labels</span> <span class="o">=</span> <span class="n">cnn6j</span><span class="p">[</span><span class="s1">&#39;predicted_labels&#39;</span><span class="p">],</span> <span class="n">label_names</span><span class="o">=</span><span class="n">label_names</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>73.83720930232558
</pre></div>
</div>
<img alt="../../_images/Example_Deep_Learning_Project_54_1.png" src="../../_images/Example_Deep_Learning_Project_54_1.png" />
</div>
</div>
<p>That is some pretty good performance based on only 6 / 24 joints!</p>
<ul class="simple">
<li><p>Can we answer our question? –&gt; YES, we can classify movement, and we can do so based on a sub-set of joints.</p></li>
<li><p>Have we reached our goals? –&gt; YES, this pilot study shows that we can decode movement type based on skeletal joint motion data.</p></li>
<li><p>Can we evaluate our hypotheses? –&gt; YES, we can now test the specific model performances and compare them.</p></li>
</ul>
<p>Good news, looks like we’re done with a first iteration of modeling!</p>
</div>
<hr class="docutils" />
<div class="section" id="step-9-model-evaluation">
<h1>Step 9: Model evaluation<a class="headerlink" href="#step-9-model-evaluation" title="Permalink to this headline">¶</a></h1>
<p>We can now see how well our model actual does, by running it to test our hypotheses. To test our hypotheses, we will group the joints into limbs:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">limb_joints</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Left Leg&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
               <span class="s1">&#39;Right Leg&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
               <span class="s1">&#39;Left Arm&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">13</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">22</span><span class="p">],</span>
               <span class="s1">&#39;Right Arm&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">14</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="mi">23</span><span class="p">],</span>
               <span class="s1">&#39;Torso&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span>
               <span class="s1">&#39;Head&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">15</span><span class="p">]}</span>
</pre></div>
</div>
</div>
</div>
<p>Our second hypothesis was that since our participants are right handed, the right arm will give as better classification performance than the left arm. We will fit the model on each individual limb, and then we can compare performance on the left and right arm.</p>
<p><strong>This should take up to ~1 minute!</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">limb_fits</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">limb</span> <span class="ow">in</span> <span class="n">limb_joints</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">*** FITTING: </span><span class="si">{</span><span class="n">limb</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

  <span class="n">joints</span> <span class="o">=</span> <span class="n">limb_joints</span><span class="p">[</span><span class="n">limb</span><span class="p">]</span>
  <span class="n">limb_fit</span> <span class="o">=</span> <span class="n">testJointModel</span><span class="p">(</span><span class="n">joints</span><span class="o">=</span><span class="n">joints</span><span class="p">)</span>
  <span class="n">limb_fits</span><span class="p">[</span><span class="n">limb</span><span class="p">]</span> <span class="o">=</span> <span class="n">limb_fit</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;limb performance: </span><span class="si">{</span><span class="n">limb_fit</span><span class="p">[</span><span class="s1">&#39;performance&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>*** FITTING: Left Leg
limb performance: 79.07%

*** FITTING: Right Leg
limb performance: 73.84%

*** FITTING: Left Arm
limb performance: 50.58%

*** FITTING: Right Arm
limb performance: 44.77%

*** FITTING: Torso
limb performance: 79.65%

*** FITTING: Head
limb performance: 48.26%
</pre></div>
</div>
</div>
</div>
<p>Every time we run this, we get something along these lines:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">***</span> <span class="n">FITTING</span><span class="p">:</span> <span class="n">LeftLeg</span>
<span class="n">limb</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">65.70</span><span class="o">%</span>
<span class="o">***</span> <span class="n">FITTING</span><span class="p">:</span> <span class="n">RightLeg</span>
<span class="n">limb</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">50.58</span><span class="o">%</span>
<span class="o">***</span> <span class="n">FITTING</span><span class="p">:</span> <span class="n">LeftArm</span>
<span class="n">limb</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">37.21</span><span class="o">%</span>
<span class="o">***</span> <span class="n">FITTING</span><span class="p">:</span> <span class="n">RightArm</span>
<span class="n">limb</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">22.09</span><span class="o">%</span>
<span class="o">***</span> <span class="n">FITTING</span><span class="p">:</span> <span class="n">Torso</span>
<span class="n">limb</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">73.84</span><span class="o">%</span>
<span class="o">***</span> <span class="n">FITTING</span><span class="p">:</span> <span class="n">Head</span>
<span class="n">limb</span> <span class="n">performance</span><span class="p">:</span> <span class="mf">39.53</span><span class="o">%</span>
</pre></div>
</div>
<p>For a formal test, you’d fit each model a number of times and let it converge by using many more epochs. We don’t really have time for that here, but the pattern is fairly clear already. The head and arms are the worst, the legs are better, and the torso usually wins!</p>
<p>The left arm seems to outperform the right arm in classifying movements. That was not what we expected. Maybe we should repeat this with left-handed participants to see if their right arm works better?</p>
<p>We still want to test our first hypothesis, which we’re not so certain about any more, given the performance above: the torso outperforms the other limbs. But that doesn’t mean that a model with arms and legs only is necessarily worse than a model with arms, legs and head and torso as well.</p>
<p>We will test each of these models six times, and take the median performance.</p>
<p><strong>This takes up to ~4 minutes!</strong> (About 2 minutes per kind of model.)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">limb_sets</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;limbs only&#39;</span><span class="p">:[</span><span class="s1">&#39;Left Leg&#39;</span><span class="p">,</span> <span class="s1">&#39;Right Leg&#39;</span><span class="p">,</span> <span class="s1">&#39;Left Arm&#39;</span><span class="p">,</span> <span class="s1">&#39;Right Arm&#39;</span><span class="p">],</span>
             <span class="s1">&#39;limbs+torso+head&#39;</span><span class="p">:[</span><span class="s1">&#39;Left Leg&#39;</span><span class="p">,</span> <span class="s1">&#39;Right Leg&#39;</span><span class="p">,</span> <span class="s1">&#39;Left Arm&#39;</span><span class="p">,</span>
                                 <span class="s1">&#39;Right Arm&#39;</span><span class="p">,</span> <span class="s1">&#39;Torso&#39;</span><span class="p">,</span> <span class="s1">&#39;Head&#39;</span><span class="p">]}</span>

<span class="k">for</span> <span class="n">limb_set</span> <span class="ow">in</span> <span class="n">limb_sets</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">*** FITTING: </span><span class="si">{</span><span class="n">limb_set</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
  
  <span class="n">limbs</span> <span class="o">=</span> <span class="n">limb_sets</span><span class="p">[</span><span class="n">limb_set</span><span class="p">]</span>

  <span class="n">joints</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">limb</span> <span class="ow">in</span> <span class="n">limbs</span><span class="p">:</span>
    <span class="n">joints</span> <span class="o">+=</span> <span class="n">limb_joints</span><span class="p">[</span><span class="n">limb</span><span class="p">]</span>

  <span class="n">performances</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">repeat</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">):</span>
    <span class="n">limb_set_fit</span> <span class="o">=</span> <span class="n">testJointModel</span><span class="p">(</span><span class="n">joints</span><span class="o">=</span><span class="n">joints</span><span class="p">)</span>
    <span class="n">performances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">limb_set_fit</span><span class="p">[</span><span class="s1">&#39;performance&#39;</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;performance: </span><span class="si">{</span><span class="n">limb_set_fit</span><span class="p">[</span><span class="s1">&#39;performance&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
  
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;median performance: </span><span class="si">{</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">performances</span><span class="p">))</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>*** FITTING: limbs only
performance: 82.56%
performance: 80.23%
performance: 72.09%
performance: 59.88%
performance: 83.14%
performance: 78.49%
median performance: 79.36%

*** FITTING: limbs+torso+head
performance: 78.49%
performance: 48.26%
performance: 85.47%
performance: 82.56%
performance: 73.84%
performance: 82.56%
median performance: 80.52%
</pre></div>
</div>
</div>
</div>
<p>The models are not converging, or perfect, but almost every time we run this cell the extra information from the torso and head do make the model perform a little better.</p>
<p>It seems that our spine is pretty fundamental for movement!</p>
<p>Maybe we should see how well we can do with a minimal number of joints measured. Can we go as low as 1 joint? For example, since we usually carry a phone in our pocket, the inertal motion units (IMU, i.e. accelerometers + gyroscopes) on a phone might be sufficient to get us some idea of movements people are making. We could test individual joints as well, or combinations of 2 or 3 joints.</p>
<p>Of course, in real life people make many more types of movements, so we might need more joints or IMU’s for decent classification. It will also be a problem to figure out when one movement type has ended and the next has begun.</p>
</div>
<hr class="docutils" />
<div class="section" id="step-10-publication">
<h1>Step 10: publication<a class="headerlink" href="#step-10-publication" title="Permalink to this headline">¶</a></h1>
<p>Let’s write a simple abstract following the guidelines…</p>
<p><strong>A. What is the phenomena</strong>?  Here summarize the part of the phenomena which your modeling addresses.</p>
<p><em>Movement is well characterized by angular joint information.</em></p>
<p><strong>B. What is the key scientific question?</strong>:  Clearly articulate the question which your modeling tries to answer.</p>
<p><em>Here, we ask how many joints are needed to accurately classify movements, and which joints are the most informative for classification.</em></p>
<p><strong>C. What was our hypothesis?</strong>:  Explain the key relationships which we relied on to simulate the phenomena.</p>
<p><em>We hypothesized that limb motion was more informative than torso motion; and we hypothesized that right side limbs carry more information about movement types than left side limbs.</em></p>
<p><strong>D. How did your modeling work?</strong> Give an overview of the model, it’s main components, and how the modeling works.  ‘’Here we … ‘’</p>
<p><em>To investigate these hypotheses, we constructed a simple 1d convolutional neuroal network (CNN) and trained it on different subsets of the publicly available MoVi dataset.</em></p>
<p><strong>E. What did you find? Did the modeling work?</strong> Explain the key outcomes of your modeling evaluation.</p>
<p><em>Contrary to our expectations, we observed that the torso was more informative for classification then the rest of the joints. Furthermore the left limbs allowed for better classification than the right limbs.</em></p>
<p><strong>F. What can you conclude?</strong> Conclude as much as you can <em>with reference to the hypothesis</em>, within the limits of the modeling.</p>
<p><em>We conclude that while our model works to classify movements from subsets of joint rotations, the specific subsets of joints that were most informative were counter to our intuition.</em></p>
<p><strong>G. What are the limitations and future directions?</strong> What is left to be learned? Briefly argue the plausibility of the approach and/or what you think is essential that may have been left out.</p>
<p><em>Since our dataset contained limited number of movement types, generalization might be limited. Furthermore, our findings might be specific for our particular choice of model. Finally, classification of continuous movement presents an additional challenge since we used already segmented motion data here.</em></p>
<blockquote>
<div><p>If we put this all in one paragraph, we have our final complete abstract. But, first, do not include the letters in <em>your</em> abstract, and second, you might need to paraphrase the answers a little so they fit together.</p>
</div></blockquote>
<br>
<p><strong>Abstract</strong></p>
<p>(A) Movement is well characterized by angular joint information.
(B) Here, we ask how many joints are needed to accurately classify movements, and which joints are the most informative for classification.
(C) We hypothesized that limb motion was more informative than torso motion; and we hypothesized that right side limbs carry more information about movement types than left side limbs.
(D) To investigate these hypotheses, we constructed a simple 1d convolutional neuroal network (CNN) and trained it on different subsets of the publicly available MoVi dataset.
(E) Contrary to our expectations, we observed that the torso was more informative for classification then the rest of the joints. Furthermore the left limbs allowed for better classification than the right limbs.
(F) We conclude that while our model works to classify movements from subsets of joint rotations, the specific subsets of joints that were most informative were counter to our intuition.
(G) Since our dataset contained limited number of movement types, generalization might be limited. Furthermore, our findings might be specific for our particular choice of model. Finally, classification of continuous movement presents an additional challenge since we used already segmented motion data here.</p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./projects/modelingsteps"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="TrainIllusionModelingProjectDL.html" title="previous page">Example Model Project: the Train Illusion</a>
    <a class='right-next' id="next-link" href="../code/intro.html" title="next page">Notebook with codes for projects</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Neuromatch<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>